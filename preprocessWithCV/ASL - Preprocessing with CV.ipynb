{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from string import ascii_uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir='./train'\n",
    "train_dir_img=train_dir+'/{}'\n",
    "\n",
    "train=[train_dir_img.format(i) for i in os.listdir(train_dir)]\n",
    "train=[f for f in train if not f.endswith('DS_Store')]\n",
    "\n",
    "val_dir='./val'\n",
    "val_dir_img=val_dir+'/{}'\n",
    "\n",
    "val=[val_dir_img.format(i) for i in os.listdir(val_dir)]\n",
    "val=[f for f in val if not f.endswith('DS_Store')]\n",
    "\n",
    "test_dir='./test'\n",
    "test_dir_img=test_dir+'/{}'\n",
    "\n",
    "test=[test_dir_img.format(i) for i in os.listdir(test_dir)]\n",
    "test=[f for f in test if not f.endswith('DS_Store')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters=[c for c in ascii_uppercase if c not in \"JZ\"]\n",
    "nrows=100\n",
    "ncolumns=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_and_process(list_of_images): \n",
    "    lower = 100\n",
    "    upper = 125\n",
    "    \n",
    "    X=[]\n",
    "    y=[]\n",
    "    for image in list_of_images:\n",
    "        img = cv2.imread(image,cv2.IMREAD_COLOR)\n",
    "        img = cv2.resize(img, (nrows, ncolumns), interpolation=cv2.INTER_CUBIC)\n",
    "        blur_img = cv2.GaussianBlur(img,(3,3),0)      \n",
    "        edge = cv2.Canny(blur_img,lower,upper)\n",
    "        \n",
    "        X.append(edge)   \n",
    "        for c in characters:\n",
    "            if c in image:\n",
    "                y.append(c)\n",
    "    \n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, train_y = read_and_process(train)\n",
    "val_X, val_y = read_and_process(val)\n",
    "test_X, test_y = read_and_process(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "OHE=OneHotEncoder(sparse=False)\n",
    "\n",
    "train_y = OHE.fit_tansform(train_y)\n",
    "val_y = OHE.fit_tansform(val_y)\n",
    "test_y = OHE.fit_tansform(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = np.reshape(np.array(train_X), (len(train_X),200,200,1))\n",
    "val_X = np.reshape(np.array(val_X), (len(val_X),200,200,1))\n",
    "test_X = np.reshape(np.array(test_X), (len(test_X),200,200,1))\n",
    "\n",
    "train_y = np.array(train_y)\n",
    "val_y = np.array(val_y)\n",
    "test_y = np.array(test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen =  ImageDataGenerator(rescale=1.0/255, \n",
    "                                    rotation_range=15,\n",
    "                                    zoom_range=0.2)\n",
    "\n",
    "val_datagen =  ImageDataGenerator(rescale=1.0/255)\n",
    "\n",
    "test_datagen =  ImageDataGenerator(rescale=1.0/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=50\n",
    "\n",
    "train_gen = train_datagen.flow(train_X,\n",
    "                               train_y,\n",
    "                               batch_size=batch_size,\n",
    "                               shuffle=True,\n",
    "                               seed=0)\n",
    "val_gen = val_datagen.flow(val_X,\n",
    "                           val_y,\n",
    "                           batch_size=batch_size,\n",
    "                           shuffle=True,\n",
    "                           seed=0)\n",
    "\n",
    "test_gen = test_datagen.flow(test_X,\n",
    "                             test_y,\n",
    "                             batch_size=batch_size,\n",
    "                             shuffle=True,\n",
    "                             seed=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from keras.layers.normalization import BatchNormalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CaffeNet(input_shape=(100,100,1),nclass=24)\n",
    "    #Instantiate an empty model\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st Convolutional Layer\n",
    "    model.add(Conv2D(filters=96, input_shape=input_shape, kernel_size=(11,11), strides=(4,4), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 2nd Convolutional Layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "    model.add(BatchNormalization())\n",
    "\n",
    "    # 3rd Convolutional Layer\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # 4th Convolutional Layer\n",
    "    model.add(Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # 5th Convolutional Layer\n",
    "    model.add(Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), padding='same'))\n",
    "    model.add(Activation('relu'))\n",
    "    # Max Pooling\n",
    "    model.add(MaxPooling2D(pool_size=(3,3), strides=(2,2), padding='same'))\n",
    "\n",
    "    # Passing it to a Fully Connected layer\n",
    "    model.add(Flatten())\n",
    "    # 1st Fully Connected Layer\n",
    "    model.add(Dense(4096))\n",
    "    model.add(Activation('relu'))\n",
    "    # Add Dropout to prevent overfitting\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # 2nd Fully Connected Layer\n",
    "    model.add(Dense(4096))\n",
    "    model.add(Activation('relu'))\n",
    "    # Add Dropout\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    # Output Layer\n",
    "    model.add(Dense(nclass))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def VGG19(input_shape=(100,100,1),nclass=24)    \n",
    "    model = Sequential()\n",
    "\n",
    "    # Block 1\n",
    "    model.add(Conv2D(filters=64,\n",
    "                     input_shape=input_shape,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(Conv2D(filters=64,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                           strides=(2, 2)))\n",
    "\n",
    "    # Block 2\n",
    "    model.add(Conv2D(filters=128,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(Conv2D(filters=128,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                           strides=(2, 2)))\n",
    "\n",
    "    # Block 3\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(Conv2D(filters=256,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                           strides=(2, 2)))\n",
    "\n",
    "    # Block 4\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                           strides=(2, 2)))\n",
    "\n",
    "    # Block 5\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(Conv2D(filters=512,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),\n",
    "                           strides=(2, 2)))\n",
    "\n",
    "    # Passing it to a Fully Connected layer\n",
    "    model.add(Flatten())\n",
    "\n",
    "    # 1st Fully Connected Layer\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "\n",
    "    # 2nd Fully Connected Layer\n",
    "    model.add(Dense(4096, activation='relu'))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(nclass, activation='softmax'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    # Compile the model\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_paper(input_shape=(100,100,1),nclass=24):\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Conv2D(filters=16,\n",
    "                     input_shape=input_shape,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(filters=32,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "    \n",
    "    model.add(Conv2D(filters=64,\n",
    "                     kernel_size=(3, 3),\n",
    "                     activation='relu',\n",
    "                     padding='same'))\n",
    "    \n",
    "    model.add(MaxPooling2D(pool_size=(5, 5)))\n",
    "    \n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(1024, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(nclass, activation='softmax'))\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "filepath = 'weight.h5'\n",
    "\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', \n",
    "                        verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "early = EarlyStopping(monitor='val_loss', \n",
    "                      mode='min', \n",
    "                      patience=4, restore_best_weights=True)\n",
    "\n",
    "callbacks_list = [checkpoint, early]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape=(nrows,ncolumns,1)\n",
    "nclass=24\n",
    "model = from_paper(input_shape,nclass)\n",
    "#model = VGG19(input_shape,nclass)\n",
    "#model = CaffeNet(input_shape,nclass)\n",
    "history = model.fit_generator(train_gen,\n",
    "                              steps_per_epoch=nclass*1000/batch_size,          \n",
    "                              validation_data=val_gen,\n",
    "                              validation_steps=batch_size, \n",
    "                              epochs=50, verbose=1,\n",
    "                              callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc)+1)\n",
    "\n",
    "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'r', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'b', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n",
    "\n",
    "plt.savefig('accuracy_loss.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
